{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9488ddb-611f-4261-a895-e74ba1f1b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure image-magick\n",
    "from moviepy.config import change_settings\n",
    "change_settings({\"IMAGEMAGICK_BINARY\": r\"C:\\Program Files\\ImageMagick-7.1.1-Q16-HDRI\\magick.exe\"})\n",
    "\n",
    "\n",
    "import moviepy.editor as mpy\n",
    "import IPython.display as ipd\n",
    "from glob import glob\n",
    "from textwrap import wrap\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d33ae-47d7-4456-91ab-6c481860b14e",
   "metadata": {},
   "source": [
    "INTRODUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de77193a-51d1-41ce-9bf0-cf0a5ca969da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video loaded...\n",
      "Moviepy - Building video intro_vid_with_txt.mp4.\n",
      "MoviePy - Writing audio in intro_vid_with_txtTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video intro_vid_with_txt.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready intro_vid_with_txt.mp4\n",
      "Video saved...\n"
     ]
    }
   ],
   "source": [
    "# Video Specifications\n",
    "target_width = 1280\n",
    "target_height = 720\n",
    "target_fps = 24\n",
    "\n",
    "# Load the video\n",
    "vid_path = r\"intro_vid.mp4\"\n",
    "audio_path = r\"effects_intro.mp3\"\n",
    "audio = mpy.AudioFileClip(audio_path)\n",
    "audio_duration = audio.duration\n",
    "video_duration = min(10, audio_duration) \n",
    "video = mpy.VideoFileClip(vid_path)\n",
    "print(\"Video loaded...\")\n",
    "\n",
    "# Prepare the text with a correctly escaped font path\n",
    "font = r\"C:\\\\Users\\\\mulwa\\\\Desktop\\\\VidsP\\\\OpenCV\\\\Allura,Briem_Hand\\BriemHand-VariableFont_wght.ttf\"\n",
    "text = \"\\nEdited and prepared in collaboration with: \\nSC205/103633/20\\nSC205/108118/21\\nSC205/108128/21\"\\\n",
    "        \"\\nSC205/108131/21\\nSC205/103973/20\"  \n",
    "txt = mpy.TextClip(text, color=\"white\", font=font, fontsize=60,\\\n",
    "                   size=(target_width - 100, None),\\\n",
    "                   method =\"caption\")\n",
    "\n",
    "                  \n",
    "# Position the text and add it to the video\n",
    "# (\"center\", \"top\")\n",
    "duration = 10\n",
    "txt = txt.set_position(lambda t: (\"center\", max(0, 0.5 - t / duration)\\\n",
    "      * video.h)).set_start((0, 1)).set_duration(duration).\\\n",
    "      crossfadein(0.5).crossfadeout(0.5)\n",
    "         \n",
    "vid_with_txt = mpy.CompositeVideoClip([video, txt])\n",
    "\n",
    "# Resize and set the frame rate\n",
    "vid_with_txt = vid_with_txt.resize(newsize=(target_width, target_height))\n",
    "vid_with_txt = vid_with_txt.set_fps(target_fps)\n",
    "vid_with_txt = vid_with_txt.set_audio(audio.subclip(0, video_duration))\n",
    "\n",
    "# Export the video\n",
    "vid_with_txt.write_videofile(\"intro_vid_with_txt.mp4\", codec=\"libx264\", fps=target_fps, threads=4, preset=\"slow\")\n",
    "print(\"Video saved...\")\n",
    "video.close()\n",
    "vid_with_txt.close()\n",
    "# ipd.Video(\"intro_vid_with_txt.mp4\", width=650, height=300, embed=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6f45d-1e8c-4ec1-8f34-5f178ceba7e7",
   "metadata": {},
   "source": [
    "INTRO II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b749d9-34c1-4311-b0d2-7e2158f80741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video intro_2.mp4.\n",
      "MoviePy - Writing audio in intro_2TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video intro_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready intro_2.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define video specifications\n",
    "video_width, video_height = 1280, 720\n",
    "audio_path = r\"introduction.mp3\"\n",
    "video_path = r\"intro_vid_2.mp4\"\n",
    "\n",
    "# Load audio and get its duration\n",
    "audio = mpy.AudioFileClip(audio_path)\n",
    "video = mpy.VideoFileClip(video_path)\n",
    "audio_duration = audio.duration\n",
    "video_duration = min(22, audio_duration)  # Ensure video duration does not exceed audio length\n",
    "\n",
    "\n",
    "# Load transcriptions from a text file\n",
    "with open(\"Introduction.txt\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Define start times and durations for each line in seconds\n",
    "start_times = [1, 2, 4, 5, 6, 8, 9, 12, 13, 16, 19] \n",
    "durations = [1, 2, 1, 1, 2, 1, 3, 1, 3, 3]       \n",
    "\n",
    "# Create and position each text segment\n",
    "clips = []\n",
    "for line, start, duration in zip(lines, start_times, durations):\n",
    "    text_clip = (\n",
    "        mpy.TextClip(line, fontsize=50, color='white', bg_color=\"black\")\n",
    "        .set_position((\"center\", \"top\"))\n",
    "        .set_start(start)\n",
    "        .set_duration(duration)\n",
    "    )\n",
    "    clips.append(text_clip)\n",
    ", \n",
    "\n",
    "\n",
    "# Combine all clips\n",
    "final_video = mpy.CompositeVideoClip([video] + clips)\n",
    "# Set audio and write the final video file\n",
    "final_video = final_video.set_audio(audio.subclip(1, video_duration))\\\n",
    ".volumex(2.0) # Double vol\n",
    "final_video.write_videofile(\"intro_2.mp4\", codec=\"libx264\", \\\n",
    "                            preset=\"slow\",  audio_codec=\"aac\")\n",
    "\n",
    "# Release resources and display video\n",
    "video.close()\n",
    "audio.close()\n",
    "# ipd.Video(\"intro_2.mp4\", width=650, height=350, embed=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f581a8b-00a0-4b4a-9e71-a0623af8f968",
   "metadata": {},
   "source": [
    "SOCIAL SRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc4274ca-3ebe-47f4-9563-8e0e4af75a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video social_structure_2.mp4.\n",
      "MoviePy - Writing audio in social_structure_2TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video social_structure_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready social_structure_2.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define video specifications\n",
    "video_width, video_height = 1280, 720\n",
    "audio_path = r\"social_structure.mp3\"\n",
    "video_path = r\"Cheetah Mom Teaches Cubs to Hunt-sub_2(360P).mp4\"\n",
    "\n",
    "# Load audio and get its duration\n",
    "audio = mpy.AudioFileClip(audio_path)\n",
    "video = mpy.VideoFileClip(video_path)\n",
    "audio_duration = audio.duration\n",
    "video_duration = min(30, audio_duration)  # Ensure video duration does not exceed audio length\n",
    "\n",
    "\n",
    "# Load transcriptions from a text file\n",
    "with open(\"social_structure.txt\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Define start times and durations for each line in seconds\n",
    "start_times = [1, 4, 6, 8, 11, 14, 15, 18, 20, 23, 27] \n",
    "durations = [3, 2, 2,  3, 3, 1, 3, 2, 3, 4]       \n",
    "\n",
    "# Create and position each text segment\n",
    "clips = []\n",
    "for line, start, duration in zip(lines, start_times, durations):\n",
    "    text_clip = (\n",
    "        mpy.TextClip(line, fontsize=50, color='white', bg_color=\"black\")\n",
    "        .set_position((\"center\", \"top\"))\n",
    "        .set_start(start)\n",
    "        .set_duration(duration)\n",
    "    )\n",
    "    clips.append(text_clip)\n",
    ", \n",
    "\n",
    "\n",
    "# Combine all clips\n",
    "final_video = mpy.CompositeVideoClip([video] + clips)\n",
    "# Set audio and write the final video file\n",
    "final_video = final_video.set_audio(audio.subclip(1, video_duration)).\\\n",
    "            volumex(3.0)\n",
    "final_video.write_videofile(\"social_structure_2.mp4\", codec=\"libx264\", preset=\"slow\",\\\n",
    "                            audio_codec=\"aac\")\n",
    "\n",
    "# Release resources and display video\n",
    "video.close()\n",
    "audio.close()\n",
    "# ipd.Video(\"social_structure_2.mp4\", width=650, height=350, embed=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b0c22-1d97-4771-a826-be4a483dc67c",
   "metadata": {},
   "source": [
    "HABITAT & RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170c58a6-035c-45c3-8697-ed32b39383f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video Habitat&Range_2.mp4.\n",
      "MoviePy - Writing audio in Habitat&Range_2TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video Habitat&Range_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Habitat&Range_2.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define video specifications\n",
    "video_width, video_height = 1280, 720\n",
    "audio_path = \"Habitat&Range.mp3\"\n",
    "video_path = \"Habitat&range.mp4\"\n",
    "\n",
    "# Load audio and get its duration\n",
    "audio = mpy.AudioFileClip(audio_path)\n",
    "video = mpy.VideoFileClip(video_path)\n",
    "audio_duration = audio.duration\n",
    "video_duration = min(30, audio_duration)  # Ensure video duration does not exceed audio length\n",
    "\n",
    "\n",
    "# Load transcriptions from a text file\n",
    "with open(\"Habitat&Range.txt\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Define start times and durations for each line in seconds\n",
    "start_times = [1, 3, 5, 6, 9, 11, 15, 17, 21] \n",
    "durations = [2, 2, 1,  3, 2, 4, 2, 4]       \n",
    "\n",
    "# Create and position each text segment\n",
    "clips = []\n",
    "for line, start, duration in zip(lines, start_times, durations):\n",
    "    text_clip = (\n",
    "        mpy.TextClip(line, fontsize=50, color='white', bg_color=\"black\")\n",
    "        .set_position((\"center\", \"center\"))\n",
    "        .set_start(start)\n",
    "        .set_duration(duration)\n",
    "    )\n",
    "    clips.append(text_clip)\n",
    ", \n",
    "\n",
    "\n",
    "# Combine all clips\n",
    "final_video = mpy.CompositeVideoClip([video] + clips)\n",
    "# Set audio and write the final video file\n",
    "final_video = final_video.set_audio(audio.subclip(1, video_duration)).\\\n",
    "            volumex(4.0)\n",
    "final_video.write_videofile(\"Habitat&Range_2.mp4\", codec=\"libx264\", preset=\"slow\",\\\n",
    "                            audio_codec=\"aac\")\n",
    "\n",
    "# Release resources and display video\n",
    "video.close()\n",
    "audio.close()\n",
    "# ipd.Video(\"Habitat&Range_2.mp4\", width=650, height=350, embed=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bca249-e542-4795-8edc-3f4f9b6b9adc",
   "metadata": {},
   "source": [
    "VISION & HUNTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f19095a-aa47-4f10-b38a-151d7f514515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video Vision&Hunting_2.mp4.\n",
      "MoviePy - Writing audio in Vision&Hunting_2TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video Vision&Hunting_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Vision&Hunting_2.mp4\n"
     ]
    }
   ],
   "source": [
    "# Define video specifications\n",
    "video_width, video_height = 1280, 720\n",
    "audio_path = \"Vision&Hunting.mp3\"\n",
    "video_path = \"Vision&Hunting.mp4\"\n",
    "\n",
    "# Load audio and get its duration\n",
    "audio = mpy.AudioFileClip(audio_path)\n",
    "video = mpy.VideoFileClip(video_path)\n",
    "audio_duration = audio.duration\n",
    "video_duration = min(30, audio_duration)  # Ensure video duration does not exceed audio length\n",
    "\n",
    "\n",
    "# Load transcriptions from a text file\n",
    "with open(\"Vision_hunting.txt\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# Define start times and durations for each line in seconds\n",
    "start_times = [2, 4, 7, 8, 11, 13, 15, 17, 18, 21, 24, 27, 30] \n",
    "durations = [2, 3, 1, 3, 2, 2, 2, 1, 3, 3, 3, 3]         \n",
    "\n",
    "# Create and position each text segment\n",
    "clips = []\n",
    "for line, start, duration in zip(lines, start_times, durations):\n",
    "    text_clip = (\n",
    "        mpy.TextClip(line, fontsize=50, color='white', bg_color=\"black\")\n",
    "        .set_position((\"center\", \"center\"))\n",
    "        .set_start(start)\n",
    "        .set_duration(duration)\n",
    "    )\n",
    "    clips.append(text_clip)\n",
    ", \n",
    "\n",
    "\n",
    "# Combine all clips\n",
    "final_video = mpy.CompositeVideoClip([video] + clips)\n",
    "# Set GEMINI_AI/Audios/Assignment/Vision&Hunting.mpaudio and write the final video file\n",
    "final_video = final_video.set_audio(audio.subclip(1, video_duration)).\\\n",
    "            volumex(2.0)\n",
    "final_video.write_videofile(\"Vision&Hunting_2.mp4\", codec=\"libx264\", preset=\"slow\",\\\n",
    "                            audio_codec=\"aac\")\n",
    "\n",
    "# Release resources and display video\n",
    "video.close()\n",
    "audio.close()\n",
    "# ipd.Video(\"Vision&Hunting_2.mp4\", width=650, height=350, embed=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874599a9-f945-460f-9e37-c3183c23981b",
   "metadata": {},
   "source": [
    "PHYSICAL ADAPTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab03bfbc-3919-43f5-a1b5-bbb941123670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video Physical_adapts_2.mp4.\n",
      "MoviePy - Writing audio in Physical_adapts_2TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video Physical_adapts_2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Physical_adapts_2.mp4\n",
      "Video saved to Physical_adapts_2.mp4\n"
     ]
    }
   ],
   "source": [
    "def create_text_clip(line, start, duration, video_width, video_height):\n",
    "    \"\"\"\n",
    "    Create a text clip that dynamically adjusts to fit within the video dimensions.\n",
    "    \n",
    "    Parameters:\n",
    "    - line: The text to display.\n",
    "    - start: Start time for the text.\n",
    "    - duration: Duration for which the text is displayed.\n",
    "    - video_width: The width of the video.\n",
    "    - video_height: The height of the video.\n",
    "    \"\"\"\n",
    "    max_width = video_width * 0.9  # 90% of video width\n",
    "    max_height = video_height * 0.2  # Use 20% of video height for text\n",
    "    font_size = 40  # Start with an initial font size\n",
    "\n",
    "    while True:\n",
    "        # Dynamically wrap the text to fit within max_width\n",
    "        wrapped_text = \"\\n\".join(wrap(line, width=int(max_width / (font_size / 2))))\n",
    "        text_clip = mpy.TextClip(wrapped_text, fontsize=font_size, color=\"white\", bg_color=\"black\")\n",
    "         # Check if the text fits within the allowed dimensions\n",
    "        if text_clip.w <= max_width and text_clip.h <= max_height:\n",
    "            break\n",
    "\n",
    "        # Reduce font size if it doesn't fit\n",
    "        font_size -= 2\n",
    "        if font_size < 10:  # Prevent infinite loop for very long text\n",
    "            raise ValueError(\"Text cannot fit within the defined window. Consider shortening the text.\")\n",
    "\n",
    "    # Center the text clip and set its start time and duration\n",
    "    return text_clip.set_position(\"center\", \"bottom\").set_start(start).set_duration(duration)\n",
    "\n",
    "# File paths\n",
    "audio_path = Path(r\"C:\\Users\\mulwa\\Desktop\\projApi\\APIS\\GEMINI_AI\\Audios\\Physical_ada.mp3\")\n",
    "text_file_path = Path(r\"Physical_adpts.txt\")\n",
    "video_path = Path(r\"Physical_adaptations.mp4\")\n",
    "\n",
    "# Validate audio file\n",
    "if not audio_path.exists():\n",
    "    raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
    "\n",
    "# Validate text file\n",
    "if not text_file_path.exists():\n",
    "    raise FileNotFoundError(f\"Text file not found: {text_file_path}\")\n",
    "\n",
    "# Load audio\n",
    "audio = mpy.AudioFileClip(str(audio_path))\n",
    "audio_duration = audio.duration  # Match video duration to audio duration\n",
    "video_duration = min(72, audio_duration)\n",
    "\n",
    "# Load Video\n",
    "video = mpy.VideoFileClip(str(video_path))\n",
    "\n",
    "# Video specifications\n",
    "video_width, video_height, fps = 1280, 720, 24\n",
    "\n",
    "# Load transcription text and create text clips\n",
    "with open(text_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = [line.strip() for line in file if line.strip()]\n",
    "\n",
    "# Define start times and durations\n",
    "start_times = [0, 1, 2, 4, 6, 8, 10, 12, 14, 18, 20, 22, 24] \n",
    "durations = [1, 1, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2] \n",
    "if len(lines) != len(durations):\n",
    "    raise ValueError(\"Mismatch: Ensure the number of lines matches start_times and durations.\")\n",
    "\n",
    "text_clips = [\n",
    "    create_text_clip(line, start, duration, video_width, video_height)\n",
    "    for line, start, duration in zip(lines, start_times, durations)\n",
    "]\n",
    "\n",
    "# Combine all clips\n",
    "all_clips = [video, *text_clips]\n",
    "final_video = mpy.CompositeVideoClip(all_clips).set_audio(audio.subclip(0, video_duration)).volumex(3.0)\n",
    "\n",
    "# Export the final video\n",
    "output_path = \"Physical_adapts_2.mp4\"\n",
    "final_video.write_videofile(output_path, fps=fps, codec=\"libx264\", audio_codec=\"aac\", preset=\"slow\")\n",
    "\n",
    "print(f\"Video saved to {output_path}\")\n",
    "# ipd.Video(\"Physical_adapts_2.mp4\", width=650, height=350, embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d06e1-e280-42a0-a45a-507edf0dbafd",
   "metadata": {},
   "source": [
    "COMBINE ALL CLIPS & ADD TITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e264ea00-fd52-4ce9-98ff-7f5c533d20b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos loaded and subclips created...\n",
      "Audio tracks concatenated successfully.\n",
      "Duration: 182.65\n",
      "Combined video duration: 181.0 seconds\n",
      "Moviepy - Building video final_vid_combined_with_audio.mp4.\n",
      "MoviePy - Writing audio in final_vid_combined_with_audioTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_vid_combined_with_audio.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_vid_combined_with_audio.mp4\n",
      "Video with combined audio saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define video paths\n",
    "paths = [\n",
    "    r\"intro_vid_with_txt.mp4\",\n",
    "    r\"intro_2.mp4\",\n",
    "    r\"Habitat&Range_2.mp4\",\n",
    "    r\"social_structure_2.mp4\",\n",
    "    r\"Vision&Hunting_2.mp4\",\n",
    "    r\"Physical_adapts_2.mp4\",\n",
    "]\n",
    "\n",
    "# Check if all files exist\n",
    "missing_files = [path for path in paths if not os.path.exists(path)]\n",
    "if missing_files:\n",
    "    print(f\"Missing files: {missing_files}\")\n",
    "    raise FileNotFoundError(\"Some video files are missing. Please check the paths.\")\n",
    "\n",
    "try:\n",
    "    # Create subclips for all videos\n",
    "    clip_list = [\n",
    "        mpy.VideoFileClip(paths[0]).subclip(\"0:00:00.0\", \"0:00:11.0\"),\n",
    "        mpy.VideoFileClip(paths[1]).subclip(\"0:00:00.0\", \"0:00:21.0\"),\n",
    "        mpy.VideoFileClip(paths[2]).subclip(\"0:00:00.0\", \"0:00:21.0\"),\n",
    "        mpy.VideoFileClip(paths[3]).subclip(\"0:00:00.0\", \"0:00:29.0\"),\n",
    "        mpy.VideoFileClip(paths[4]).subclip(\"0:00:03.0\", \"0:00:30.0\"),\n",
    "        mpy.VideoFileClip(paths[5]).subclip(\"0:00:00.0\", \"00:00:72.0\"),\n",
    "    ]\n",
    "\n",
    "    print(\"Videos loaded and subclips created...\")\n",
    "\n",
    "    # Extract and concatenate audio tracks\n",
    "    audio_list = [r\"effects_intro_2.mp3\",\n",
    "                  r\"introduction.mp3\",\n",
    "                  r\"Habitat&Range.mp3\",\n",
    "                  r\"social_structure.mp3\",\n",
    "                  r\"Vision&Hunting_2.mp3\",\n",
    "                  r\"Physical_ada_fit_2.mp3\",\n",
    "                  r\"effects_hunting.mp3\",\n",
    "                  r\"effects_hunting_2.mp3\"\n",
    "                 ]\n",
    "\n",
    "      # Load and concatenate audio clips\n",
    "    audio_clips = [mpy.AudioFileClip(audio_path) for audio_path in audio_list]\n",
    "    concatenated_audio = mpy.concatenate_audioclips(audio_clips)\n",
    "    print(\"Audio tracks concatenated successfully.\")\n",
    "    print(f\"Duration: {concatenated_audio.duration}\")\n",
    "\n",
    "    # Define target dimensions and FPS\n",
    "    target_width, target_height, target_fps = 1280, 720, 24\n",
    "\n",
    "    # Process and resize clips\n",
    "    processed_clips = [\n",
    "        clip.resize(newsize=(target_width, target_height)).set_fps(target_fps)\n",
    "        for clip in clip_list\n",
    "    ]\n",
    "\n",
    "    # Combine all clips\n",
    "    combined_video = mpy.concatenate_videoclips(processed_clips, method=\"compose\")\n",
    "    print(f\"Combined video duration: {combined_video.duration} seconds\")\n",
    "\n",
    "    # Set the concatenated audio to the combined video\n",
    "    video_duration = combined_video.duration\n",
    "    combined_video = combined_video.set_audio(concatenated_audio.subclip(0, video_duration)).volumex(2.5)\n",
    "\n",
    "    # Define output path\n",
    "    output_path = r\"final_vid_combined_with_audio.mp4\"\n",
    "\n",
    "    # Write the final video\n",
    "    combined_video.write_videofile(\n",
    "        output_path, codec=\"libx264\", preset=\"slow\", audio_codec=\"aac\", bitrate=\"2000k\"\n",
    "    )\n",
    "    print(\"Video with combined audio saved successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}. Please check your setup and paths.\")\n",
    "\n",
    "finally:\n",
    "    # Release resources\n",
    "    for clip in clip_list + processed_clips:\n",
    "        clip.close()\n",
    "    if concatenated_audio:\n",
    "        concatenated_audio.close()\n",
    "\n",
    "# Display the final video (for Jupyter Notebook or IPython environments)\n",
    "# ipd.Video(output_path, width=650, height=350, embed=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c546c-127c-4e90-b5be-995b64732b02",
   "metadata": {},
   "source": [
    "ADD SUBTITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6421739-0a23-47e8-9fa9-aabf4a4864e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video final_vid_combined_with_audio_with_subtitles.mp4.\n",
      "MoviePy - Writing audio in final_vid_combined_with_audio_with_subtitlesTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video final_vid_combined_with_audio_with_subtitles.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready final_vid_combined_with_audio_with_subtitles.mp4\n",
      "Video saved to final_vid_combined_with_audio_with_subtitles.mp4\n"
     ]
    }
   ],
   "source": [
    "# An helper function to parse an srt\n",
    "def parse_srt(srt_path):\n",
    "    \"\"\"\n",
    "    Parse an SRT file and return a list of subtitle entries.\n",
    "    Each entry is a dictionary with 'start', 'end', and 'text' keys.\n",
    "    \"\"\"\n",
    "    subtitles = []\n",
    "    with open(srt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read().strip().split(\"\\n\\n\")\n",
    "        for block in content:\n",
    "            lines = block.split(\"\\n\")\n",
    "            if len(lines) >= 3:\n",
    "                time_range = lines[1]\n",
    "                start, end = time_range.split(\" --> \")\n",
    "                text = \" \".join(lines[2:])\n",
    "                subtitles.append({\n",
    "                    \"start\": parse_time(start),\n",
    "                    \"end\": parse_time(end),\n",
    "                    \"text\": text\n",
    "                })\n",
    "    return subtitles\n",
    "\n",
    "\n",
    "def parse_time(timestamp):\n",
    "    \"\"\"\n",
    "    Parse an SRT timestamp (e.g., '00:00:05,000') into seconds.\n",
    "    \"\"\"\n",
    "    h, m, s = timestamp.replace(\",\", \".\").split(\":\")\n",
    "    return float(h) * 3600 + float(m) * 60 + float(s)\n",
    "\n",
    "\n",
    "def create_subtitle_clip(subtitle, video_width):\n",
    "    \"\"\"\n",
    "    Create a subtitle text clip for a given subtitle entry.\n",
    "    \"\"\"\n",
    "    wrapped_text = \"\\n\".join(wrap(subtitle[\"text\"], width=40))  \n",
    "    font_size = 40\n",
    "    text_clip = (\n",
    "        mpy.TextClip(\n",
    "            wrapped_text, fontsize=font_size, color=\"red\", bg_color=\"white\", size=(video_width, None), method=\"caption\"\n",
    "        )\n",
    "        .set_position((\"center\", \"bottom\"))\n",
    "        .set_start(subtitle[\"start\"])\n",
    "        .set_duration(subtitle[\"end\"] - subtitle[\"start\"])\n",
    "    )\n",
    "    return text_clip\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "srt_path = Path(r\"subtitles.srt\")\n",
    "video_path = Path(r\"final_vid_combined_with_audio.mp4\")\n",
    "\n",
    "# Validate subtitle file\n",
    "if not srt_path.exists():\n",
    "    raise FileNotFoundError(f\"SRT file not found: {srt_path}\")\n",
    "\n",
    "# Validate video file\n",
    "if not video_path.exists():\n",
    "    raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "\n",
    "\n",
    "# Parse subtitles and create subtitle clips\n",
    "subtitles = parse_srt(srt_path)\n",
    "video = mpy.VideoFileClip(str(video_path))\n",
    "video_width = video.size[0]\n",
    "\n",
    "subtitle_clips = [create_subtitle_clip(sub, video_width) for sub in subtitles]\n",
    "\n",
    "# Combine video and subtitles\n",
    "all_clips = [video, *subtitle_clips]\n",
    "final_video = mpy.CompositeVideoClip(all_clips).volumex(2.5)\n",
    "\n",
    "# Export the final video\n",
    "try:\n",
    "    output_path = \"final_vid_combined_with_audio_with_subtitles.mp4\"\n",
    "    final_video.write_videofile(\n",
    "        output_path, fps=video.fps, codec=\"libx264\", audio_codec=\"aac\", preset=\"slow\"\n",
    "    )\n",
    "    print(f\"Video saved to {output_path}\")\n",
    "\n",
    "finally:\n",
    "    # Release resources\n",
    "    if video:\n",
    "        video.close()\n",
    "    if final_video:\n",
    "        final_video.close()\n",
    "    for clip in subtitle_clips:\n",
    "        clip.close()\n",
    "        \n",
    "# Display the video\n",
    "# ipd.Video(\"final_vid_combined_with_audio_with_subtitles.mp4\", width=650, height=350, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9022417-d581-406a-9c13-2546b4045c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 8282-216D\n",
      "\n",
      " Directory of C:\\Users\\mulwa\\Desktop\\projApi\\APIS\\GEMINI_AI\\Audios\\Assignment\n",
      "\n",
      "12/07/2024  08:27 AM    <DIR>          .\n",
      "12/07/2024  08:27 AM    <DIR>          ..\n",
      "12/03/2024  06:10 AM    <DIR>          .ipynb_checkpoints\n",
      "12/07/2024  08:27 AM            39,806 Assignment_01_.ipynb\n",
      "11/30/2024  10:51 PM           515,002 AUD-20241130-WA0001.mp3\n",
      "11/30/2024  10:51 PM           229,624 AUD-20241130-WA0002.aac\n",
      "11/30/2024  10:51 PM           177,247 AUD-20241130-WA0003.m4a\n",
      "11/03/2024  11:52 AM        10,768,025 Cheetah - Fastest Running Animal - 1080 HD(360P).mp4\n",
      "12/01/2024  07:16 AM         9,975,986 Cheetah Mom Teaches Cubs to Hunt-sub(360P).mp4\n",
      "12/01/2024  12:37 PM         5,746,424 Cheetah Mom Teaches Cubs to Hunt-sub_2(360P).mp4\n",
      "12/01/2024  08:17 AM         1,930,388 effects.mp3\n",
      "12/01/2024  08:29 AM           480,906 effects_hunting.mp3\n",
      "12/01/2024  08:30 AM           320,827 effects_hunting_2.mp3\n",
      "12/01/2024  08:21 AM           256,879 effects_intro.mp3\n",
      "12/02/2024  09:10 AM           177,049 effects_intro_2.mp3\n",
      "12/02/2024  07:49 AM        37,688,936 final_vid_combined.mp4\n",
      "12/05/2024  12:41 PM        48,843,244 final_vid_combined_with_audio.mp4\n",
      "12/07/2024  08:03 AM        41,228,172 final_vid_combined_with_audio_with_subtitles.mp4\n",
      "12/01/2024  02:03 PM           342,143 Habitat&Range.mp3\n",
      "12/01/2024  02:13 PM         5,047,166 Habitat&range.mp4\n",
      "12/01/2024  02:18 PM               275 Habitat&Range.txt\n",
      "12/05/2024  12:30 PM         4,932,405 Habitat&Range_2.mp4\n",
      "12/05/2024  12:28 PM         5,202,105 intro_2.mp4\n",
      "12/01/2024  09:43 AM         2,096,252 intro_vid.mp4\n",
      "12/01/2024  09:51 AM         5,548,631 intro_vid_2.mp4\n",
      "12/05/2024  12:27 PM         3,325,684 intro_vid_with_txt.mp4\n",
      "12/01/2024  10:10 AM           304,945 introduction.mp3\n",
      "12/01/2024  10:23 AM               335 Introduction.txt\n",
      "12/01/2024  07:07 PM           402,329 Physical_ada_fit.mp3\n",
      "12/02/2024  10:22 AM           401,075 Physical_ada_fit_2.mp3\n",
      "12/02/2024  06:51 PM        16,699,033 Physical_adaptations.mp4\n",
      "12/05/2024  12:34 PM        16,668,146 Physical_adapts_2.mp4\n",
      "12/02/2024  05:40 AM               415 Physical_adpts.txt\n",
      "12/01/2024  02:02 PM            42,974 PTT-20241201-WA0005.opus\n",
      "12/01/2024  11:00 AM           448,723 social_structure.mp3\n",
      "12/01/2024  11:22 AM         4,205,376 social_structure.mp4\n",
      "12/02/2024  12:03 PM               384 social_structure.txt\n",
      "12/05/2024  12:29 PM         5,790,226 social_structure_2.mp4\n",
      "11/09/2024  09:51 PM        44,126,135 study_ecology_cheetah.mp4\n",
      "12/03/2024  06:28 AM               357 subtitles.srt\n",
      "12/01/2024  02:39 PM           489,683 Vision&Hunting.mp3\n",
      "12/01/2024  03:08 PM         7,806,516 Vision&Hunting.mp4\n",
      "12/02/2024  10:27 AM           448,723 Vision&Hunting_2.mp3\n",
      "12/05/2024  12:31 PM         7,713,710 Vision&Hunting_2.mp4\n",
      "12/01/2024  03:57 PM               451 Vision_hunting.txt\n",
      "              42 File(s)    290,422,712 bytes\n",
      "               3 Dir(s)  117,882,060,800 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32724c3-8c07-495e-b5cd-7ee403a0a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define video paths\n",
    "# paths = [\n",
    "#     r\"intro_vid_with_txt.mp4\",\n",
    "#     r\"intro_2.mp4\",\n",
    "#     r\"Habitat&Range_2.mp4\",\n",
    "#     r\"social_structure_2.mp4\",\n",
    "#     r\"Vision&Hunting_2.mp4\",\n",
    "#     r\"Physical_adapts_2.mp4\",\n",
    "# ]\n",
    "\n",
    "# # Check if all files exist\n",
    "# missing_files = [path for path in paths if not os.path.exists(path)]\n",
    "# if missing_files:\n",
    "#     print(f\"Missing files: {missing_files}\")\n",
    "#     raise FileNotFoundError(\"Some video files are missing. Please check the paths.\")\n",
    "\n",
    "# try:\n",
    "#     # Create subclips for all videos\n",
    "#     clip_list = [\n",
    "#         mpy.VideoFileClip(paths[0]).subclip(\"0:00:00.0\", \"0:00:11.0\"),\n",
    "#         mpy.VideoFileClip(paths[1]).subclip(\"0:00:00.0\", \"0:00:21.0\"),\n",
    "#         mpy.VideoFileClip(paths[2]).subclip(\"0:00:00.0\", \"0:00:21.0\"),\n",
    "#         mpy.VideoFileClip(paths[3]).subclip(\"0:00:00.0\", \"0:00:29.0\"),\n",
    "#         mpy.VideoFileClip(paths[4]).subclip(\"0:00:03.0\", \"0:00:30.0\"),\n",
    "#         mpy.VideoFileClip(paths[5]).subclip(\"0:00:00.0\", \"00:00:55.0\"),\n",
    "#     ]\n",
    "\n",
    "#     print(\"Videos loaded and subclips created...\")\n",
    "\n",
    "#     # Define target dimensions and FPS\n",
    "#     target_width, target_height, target_fps = 1280, 720, 24\n",
    "\n",
    "#     # Process and resize clips\n",
    "#     processed_clips = [\n",
    "#         clip.resize(newsize=(target_width, target_height)).set_fps(target_fps)\n",
    "#         for clip in clip_list\n",
    "#     ]\n",
    "\n",
    "#     # Combine all clips\n",
    "#     combined_video = mpy.concatenate_videoclips(processed_clips, method=\"compose\")\n",
    "#     print(f\"Combined video duration: {combined_video.duration} seconds\")\n",
    "\n",
    "#     # Define output path\n",
    "#     output_path = r\"final_vid_combined.mp4\"\n",
    "\n",
    "#     # Write the final video\n",
    "#     combined_video.write_videofile(\n",
    "#         output_path, codec=\"libx264\", preset=\"slow\", audio_codec=\"aac\"\n",
    "#     )\n",
    "#     print(\"Video saved successfully!\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}. Please check your setup and paths.\")\n",
    "\n",
    "# finally:\n",
    "#     # Release resources\n",
    "#     for clip in clip_list:\n",
    "#         clip.close()\n",
    "\n",
    "# # Display the final video (for Jupyter Notebook or IPython environments)\n",
    "# ipd.Video(output_path, width=650, height=350, embed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1472c-3c95-4659-9a38-0c68487ffd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = r\"Cheetah Mom Teaches Cubs to Hunt-sub(360P).mp4\"\n",
    "# video_path2 = r\"study_ecology_cheetah.mp4\"\n",
    "# video = mpy.VideoFileClip(video_path)\n",
    "# audio_path = r\"Vision&Hunting.mp3\"\n",
    "# audio = mpy.AudioFileClip(audio_path).subclip(\"00:00:02.0\", \"00:00:30.0\")\n",
    "# video2 = mpy.VideoFileClip(video_path2)\n",
    "# out_path = r\"C:\\Users\\p3mulwa\\Desktop\\projApi\\APIS\\GEMINI_AI\\Audios\\Physical_ada_2.mp3\"\n",
    "# out_path2 = r\"Vision&Hunting_2.mp3\"\n",
    "# # final_video = video.subclip(\"00:00:00.0\", \"00:00:28.0\")\n",
    "# # final_video = final_video.write_videofile(out_path2)                            \n",
    "# final_audio = audio.write_audiofile(out_path2)\n",
    "\n",
    "# video.close()\n",
    "# video2.close()\n",
    "# audio.close()\n",
    "\n",
    "# # ipd.Video(video_path2, width=650, height=350, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac6731-de5b-4775-95e5-6de138369635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipd.Audio(\"Vision&Hunting_2.mp3\")\n",
    "# # ipd.Video(r\"Physical_adaptations.mp4\", width=650, height=350, embed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APIS",
   "language": "python",
   "name": "apis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
